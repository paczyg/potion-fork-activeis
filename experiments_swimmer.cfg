[DEFAULT]
env = swimmer
path = results_swimmer
repetitions = 5
iterations = 1

# Policy
mu_init = None
logstd_init = 0.0
learn_std = False

# Environment
horizon = 100
gamma = 0.995

# Common algorithm parameters
baseline = 'avg'
estimator = 'gpomdp'
seed = 42

# Offpolicy algorithm parameters
ce_divergence = 'kl'
ce_tol_grad = 1e-4
ce_lr = 1e-5
ce_max_iter = 1e5
ce_batchsizes = '[100]'
batchsize = 10

[iterations]
experiment = list
ce_max_iter = [1e3, 1e4, 1e5]

[learning_rate]
experiment = list
ce_lr = [1e-3, 1e-4, 1e-5]

[batches]
experiment = list
ce_batchsizes = [[10], [20], [50], [100]]